{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X11QtSmiMV9e"
      },
      "source": [
        "# Hola, mundo en LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drFyYyIWMavB"
      },
      "source": [
        "## Instalar librerías principales y configuración de API Key de OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z_Xi-GvMf8E"
      },
      "source": [
        "## Carga de documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_6B2k3Vcfxt",
        "outputId": "184d01bf-6b36-401d-8fea-0633a6520cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargado paper1.pdf\n",
            "Descargado paper2.pdf\n",
            "Descargado paper3.pdf\n",
            "Descargado paper4.pdf\n",
            "Descargado paper5.pdf\n",
            "Contenido de ml_papers:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hacer la llamada del API\n",
        "import requests\n",
        "# Hacer el documento legible para el modelo\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# El modelo de OpenAI no tiene esta información\n",
        "\n",
        "urls = [\n",
        "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
        "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
        "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
        "]\n",
        "\n",
        "ml_papers = []\n",
        "for i, url in enumerate(urls):\n",
        "    response = requests.get(url)\n",
        "    filename = f'paper{i+1}.pdf'\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "        print(f'Descargado {filename}')\n",
        "        \n",
        "        loader = PyPDFLoader(filename)\n",
        "        data = loader.load()\n",
        "        ml_papers.extend(data)\n",
        "        \n",
        "\n",
        "\n",
        "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
        "print('Contenido de ml_papers:')\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(list,\n",
              " 57,\n",
              " Document(page_content='Figure 1: FinGPT Framework.\\n4.1 Data Sources\\nThe first stage of the FinGPT pipeline involves the collec-\\ntion of extensive financial data from a wide array of online\\nsources. These include, but are not limited to:\\n•Financial news: Websites such as Reuters, CNBC, Yahoo\\nFinance, among others, are rich sources of financial news\\nand market updates. These sites provide valuable informa-\\ntion on market trends, company earnings, macroeconomic\\nindicators, and other financial events.\\n•Social media : Platforms such as Twitter, Facebook, Red-\\ndit, Weibo, and others, offer a wealth of information in\\nterms of public sentiment, trending topics, and immediate\\nreactions to financial news and events.\\n•Filings : Websites of financial regulatory authorities, such\\nas the SEC in the United States, offer access to company\\nfilings. These filings include annual reports, quarterly earn-\\nings, insider trading reports, and other important company-\\nspecific information. Official websites of stock exchanges\\n(NYSE, NASDAQ, Shanghai Stock Exchange, etc.) pro-\\nvide crucial data on stock prices, trading volumes, company\\nlistings, historical data, and other related information.\\n•Trends : Websites like Seeking Alpha, Google Trends, and\\nother finance-focused blogs and forums provide access to\\nanalysts’ opinions, market predictions, the movement of\\nspecific securities or market segments and investment ad-\\nvice.•Academic datasets : Research-based datasets that offer cu-\\nrated and verified information for sophisticated financial\\nanalysis.\\nTo harness the wealth of information from these diverse\\nsources, FinGPT incorporates data acquisition tools capable\\nof scraping structured and unstructured data, including APIs,\\nweb scraping tools, and direct database access where avail-\\nable. Moreover, the system is designed to respect the terms\\nof service of these platforms, ensuring data collection is ethi-\\ncal and legal.\\nData APIs : In the FinGPT framework, APIs are used not\\nonly for initial data collection but also for real-time data up-\\ndates, ensuring the model is trained on the most current data.\\nAdditionally, error handling and rate-limiting strategies are\\nimplemented to respect API usage limits and avoid disrup-\\ntions in the data flow.\\n4.2 Real-Time Data Engineering Pipeline for\\nFinancial NLP\\nFinancial markets operate in real-time and are highly sensi-\\ntive to news and sentiment. Prices of securities can change\\nrapidly in response to new information, and delays in pro-\\ncessing that information can result in missed opportunities or\\nincreased risk. As a result, real-time processing is essential in\\nfinancial NLP.\\nThe primary challenge with a real-time NLP pipeline is\\nmanaging and processing the continuous inflow of data ef-\\nficiently. The first step in the pipeline is to set up a system to', metadata={'source': 'paper1.pdf', 'page': 3}))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ml_papers), len(ml_papers), ml_papers[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgGa9MHqtvHr"
      },
      "source": [
        "Uní todos los papaers cargados, veo cómo se componen los papers y el loader\n",
        "Type es una lista\n",
        "Cuantos (len) -> 57\n",
        "Tomo el elemento 4 y miro que información tiene"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJYjDA_GMi0Z"
      },
      "source": [
        "## Split de documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Antes de volverlos Embeddings debo partir la info\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(ml_papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(211,\n",
              " Document(page_content='ing untapped potentials in open finance.\\n•Data-centric approach : Recognizing the significance of\\ndata curation, FinGPT adopts a data-centric approach and\\nimplements rigorous cleaning and preprocessing methods\\nfor handling varied data formats and types, thereby ensur-\\ning high-quality data.\\n•End-to-end framework : FinGPT embraces a full-stack\\nframework for FinLLMs with four layers:\\n–Data source layer : This layer assures comprehensive\\nmarket coverage, addressing the temporal sensitivityarXiv:2306.06031v1  [q-fin.ST]  9 Jun 2023', metadata={'source': 'paper1.pdf', 'page': 0}))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents), documents[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vVcJ7yLuHFR"
      },
      "source": [
        "Convertir el texto en embeddings, el modelo solo acepta cierto número de tokenes, entonces hay que hacerlos más pequeños. No puedo ingresar todos los documentos, debo partirlos en documentos más pequeños. Convertirlo en números"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzlBqlEYvhXR"
      },
      "source": [
        "Ya puedo alimentar el modelo de embeddings e ingresarlos en una base de datos de vectores con Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGSuQV6MmOA"
      },
      "source": [
        "## Embeddings e ingesta a base de datos vectorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\":3}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBbAhkFKMrDC"
      },
      "source": [
        "## Modelos de chat y cadenas para consulta de información"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=chat,\n",
        "    chain_type='stuff',\n",
        "    retriever=retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'FinGPT is a model that focuses on open finance and adopts a data-centric approach with rigorous cleaning and preprocessing methods to ensure high-quality data. It embraces a full-stack framework for FinLLMs with four layers, including a data source layer for comprehensive market coverage. Additionally, FinGPT offers hands-on tutorials and demo applications for financial tasks like robo-advisory services, quantitative trading, and low-code development, showcasing the practical applicability of LLMs in finance.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'what is fingpt?'\n",
        "qa_chain.run(query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
